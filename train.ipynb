{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckpb03qq0r7T"
   },
   "source": [
    "#1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MV5d_15g05aK"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vnntZ7Iae7u9"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "frame_size = (224, 224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Changeable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import custom_resnets\n",
    "import custom_densenets\n",
    "\n",
    "# Set the parameter for reproducible results\n",
    "random_seed = 21 # 21, 42 or 84\n",
    "\n",
    "train_dataset_path = 'dataset/oai224/test'\n",
    "classes_header = [\"0\", \"1\", \"2\", \"3\", \"4\"] \n",
    "n_classes = len(classes_header)\n",
    "\n",
    "# Choose CNN architecture and output directory\n",
    "\n",
    "# cnn_model = custom_densenets.se_densenet121_model(n_classes)\n",
    "# cnn_model = custom_densenets.densenet121_model(n_classes)\n",
    "# cnn_model = custom_resnets.resnet18_model(n_classes)\n",
    "# cnn_model = custom_resnets.resnet34_model(n_classes)\n",
    "# cnn_model = custom_resnets.resnet50_model(n_classes)\n",
    "# cnn_model = custom_resnets.se_resnet18_model(n_classes)\n",
    "# cnn_model = custom_resnets.se_resnet34_model(n_classes)\n",
    "# cnn_model = custom_resnets.se_resnet50_model(n_classes)\n",
    "\n",
    "cnn_model = custom_densenets.se_densenet121_model(n_classes)\n",
    "checkpoints_dir = 'output/se_densenet121_' + str(random_seed) + '/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# if you are suing GPU\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Split dataset to train and validation subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "FBrdbRytzh7f",
    "outputId": "5f319fcc-85ac-40ce-c98f-960c2e3cdcea"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "validation_split = .125\n",
    "\n",
    "# Разделяем данные на тренировочные и валидационные\n",
    "transforms_to_train = transforms.Compose([         \n",
    "              transforms.ColorJitter(brightness=.33, saturation=.33),\n",
    "              transforms.RandomHorizontalFlip(p=0.5),\n",
    "              transforms.RandomAffine(degrees=(-10, 10), scale=(0.9, 1.10)),\n",
    "              transforms.Resize(frame_size), \n",
    "\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "            ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dataset_path, transform=transforms_to_train)\n",
    "targets = train_dataset.targets\n",
    "\n",
    "train_idx, valid_idx = model_selection.train_test_split(\n",
    "    np.arange(len(train_dataset.targets)), test_size=validation_split, random_state=42, shuffle=True, stratify=targets)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "qrYfLdttzzUv",
    "outputId": "4f5bf5e3-b585-42d5-d5dd-4b0316e11f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: CPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available(): # Let's make sure GPU is available!\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device_name = 'cuda:0'\n",
    "    print(\"device: CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device_name = 'cpu'\n",
    "    print(\"device: CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "73a4C1Ebz9p9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import utils\n",
    "\n",
    "def append_to_file(filename, val):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(\"%s\\n\" % val)\n",
    "\n",
    "def read_file(filename):\n",
    "    lines = []\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [float(line.strip()) for line in f]\n",
    "\n",
    "    return lines\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, lr_scheduler = None, anneal_epoch = 0): \n",
    "    if not os.path.exists(checkpoints_dir):\n",
    "        os.makedirs(checkpoints_dir)\n",
    "\n",
    "    start_epoch = 0\n",
    "\n",
    "    open(checkpoints_dir + 'loss_history.txt', 'w').close()\n",
    "    open(checkpoints_dir + 'train_history.txt', 'w').close()\n",
    "    open(checkpoints_dir + 'val_history.txt', 'w').close()\n",
    "    open(checkpoints_dir + 'best_accuracy.txt', 'w').close()\n",
    "    print(\"start traning from scratch...\")\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # process batches\n",
    "        for i_step, (x, y) in enumerate(train_loader): \n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)    \n",
    "\n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        # check accuracy\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "\n",
    "        val_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "          val_accuracy, _, _, _ = utils.compute_accuracy(model, val_loader)\n",
    "\n",
    "        # write marks to files\n",
    "        append_to_file(checkpoints_dir + 'loss_history.txt', float(ave_loss))\n",
    "        append_to_file(checkpoints_dir + 'train_history.txt', train_accuracy)\n",
    "        append_to_file(checkpoints_dir + 'val_history.txt', val_accuracy)\n",
    "\n",
    "        # update learning rate\n",
    "        if lr_scheduler is not None and epoch >= anneal_epoch:\n",
    "          lr_scheduler.step()\n",
    "        \n",
    "        stage = epoch + start_epoch\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "          best_val_accuracy = val_accuracy\n",
    "          \n",
    "          # best model\n",
    "          model_save_name = 'best_model.ckpt'\n",
    "          torch.save(model.state_dict(), checkpoints_dir + F\"{model_save_name}\")\n",
    "\n",
    "          append_to_file(checkpoints_dir + 'best_accuracy.txt', best_val_accuracy)\n",
    "          print(\"update best model with val. accuracy %f on stage %d\" % (best_val_accuracy, stage))\n",
    "\n",
    "        print(\"epoch %d; average loss: %f, train accuracy: %f, val accuracy: %f\" % (stage, ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    print(\"final best accuracy: %f\" % (best_val_accuracy))\n",
    "\n",
    "    return loss_history, train_history, val_history\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7_HKIKFrCjhU",
    "outputId": "2148f9cd-eb1d-4a69-96b2-ac54cef8b036"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-82aaf9343c9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m71\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-710990b6da63>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, loss, optimizer, num_epochs, lr_scheduler, anneal_epoch)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "if device_name.startswith('cpu'):\n",
    "    cnn_model.type(torch.FloatTensor)\n",
    "    cnn_model.to(device)\n",
    "else:\n",
    "    cnn_model.type(torch.cuda.FloatTensor)\n",
    "    cnn_model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.95) # decrease lr by 5% every 5 epochs\n",
    "\n",
    "loss_history, train_history, val_history = \\\n",
    "    train_model(cnn_model, train_loader, val_loader, loss, optimizer, 71, lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-QIpuZWK7ec"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_history = read_file(checkpoints_dir + 'train_history.txt')\n",
    "val_history = read_file(checkpoints_dir + 'val_history.txt')\n",
    "\n",
    "# vizualize accuracy\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)\n",
    "plt.savefig(checkpoints_dir + 'graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23dae643609f49d0bab5b0cd8670fab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "38e7a7d81083472fafbc008b01ae61a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d3257c1d2644c5b95549e1031cc17e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69bfa5b5717643a7bf7c6d6fbd3908b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6fd2de1132b4561aa89dbef1e0717f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d3257c1d2644c5b95549e1031cc17e6",
      "placeholder": "​",
      "style": "IPY_MODEL_69bfa5b5717643a7bf7c6d6fbd3908b4",
      "value": " 30.8M/30.8M [00:00&lt;00:00, 127MB/s]"
     }
    },
    "d6a09f76263246a19b8fab8d0ab69715": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f67a559f843b4726a8ca792110abae49",
       "IPY_MODEL_c6fd2de1132b4561aa89dbef1e0717f4"
      ],
      "layout": "IPY_MODEL_df2bfc187cd14a25922255bca08e8891"
     }
    },
    "df2bfc187cd14a25922255bca08e8891": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f67a559f843b4726a8ca792110abae49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38e7a7d81083472fafbc008b01ae61a3",
      "max": 32342954,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23dae643609f49d0bab5b0cd8670fab3",
      "value": 32342954
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
